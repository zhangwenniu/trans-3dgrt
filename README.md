<p align="center">
  <img height="100" src="assets/3dgrut_logo.png">
</p>

---
<p align="center">
  <img width="100%" src="assets/nvidia-hq-playground.gif">
</p>

This repository provides the official implementations of **3D Gaussian Ray Tracing (3DGRT)** and **3D Gaussian Unscented Transform (3DGUT)**. Unlike traditional methods that rely on splatting, 3DGRT performs ray tracing of volumetric Gaussian particles instead. This enables support for distorted cameras with complex, time-dependent effects such as rolling shutters, while also efficiently simulating secondary rays required for rendering phenomena like reflection, refraction, and shadows. However, 3DGRT requires dedicated ray-tracing hardware and remains slower than 3DGS.

To mitigate this limitation, we also propose 3DGUT, which enables support for distorted cameras with complex, time-dependent effects within a rasterization framework, maintaining the efficiency of rasterization methods. By aligning the rendering formulations of 3DGRT and 3DGUT, we introduce a hybrid approach called **3DGRUT**. This technique allows for rendering primary rays via rasterization and secondary rays via ray tracing, combining the strengths of both methods for improved performance and flexibility.


> __3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes__  
> [Nicolas Moenne-Loccoz*](https://www.linkedin.com/in/nicolas-moÃ«nne-loccoz-71040512/?original_referer=https%3A%2F%2Fwww%2Egoogle%2Ecom%2F&originalSubdomain=ca), [Ashkan Mirzaei*](https://ashmrz.github.io), [Or Perel](https://orperel.github.io/), [Riccardo De Lutio](https://riccardodelutio.github.io/), [Janick Martinez Esturo](https://jme.pub/),   
> [Gavriel State](https://www.linkedin.com/in/gavstate/?originalSubdomain=ca), [Sanja Fidler](https://www.cs.utoronto.ca/~fidler/), [Nicholas Sharp^](https://nmwsharp.com/), [Zan Gojcic^](https://zgojcic.github.io/) _(*,^ indicates equal contribution)_  
> _SIGGRAPH Asia 2024 (Journal Track)_  
> __[Project page](https://research.nvidia.com/labs/toronto-ai/3DGRT)&nbsp;/ [Paper](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_compressed.pdf)&nbsp;/ [Video](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_supplementary_video.mp4)&nbsp;/ [BibTeX](/-/raw/release/assets/3dgrt2024.bib)__

> __3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting__  
> [Qi Wu*](https://wilsoncernwq.github.io/), [Janick Martinez Esturo*](https://jme.pub/), [Ashkan Mirzaei](https://ashmrz.github.io),   
> [Nicolas Moenne-Loccoz](https://www.linkedin.com/in/nicolas-moÃ«nne-loccoz-71040512/?original_referer=https%3A%2F%2Fwww%2Egoogle%2Ecom%2F&originalSubdomain=ca), [Zan Gojcic](https://zgojcic.github.io/)  _(* indicates equal contribution)_  
> _CVPR 2025_  
> __[Project page](https://research.nvidia.com/labs/toronto-ai/3DGUT)&nbsp;/ [Paper](https://research.nvidia.com/labs/toronto-ai/3DGUT/res/3DGUT_ready_main.pdf)&nbsp;/ [Video](https://research.nvidia.com/labs/toronto-ai/3DGUT/#supp_video)&nbsp;/ [BibTeX](/-/raw/release/assets/3dgut2025.bib)__


## ğŸ”¥ News
- âœ…[2025/03] Initial code release!
- âœ…[2025/02] [3DGUT](https://research.nvidia.com/labs/toronto-ai/3DGUT/res/3DGUT_ready_main.pdf) was accepted to CVPR 2025!
- âœ…[2024/08] [3DGRT](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_compressed.pdf) was accepted to SIGGRAPH Asia 2024!

## Contents

- [ğŸ”¥ News](#-news)
- [Contents](#contents)
- [ğŸ”§ 1 Dependencies and Installation](#-1-dependencies-and-installation)
- [ğŸ’» 2. Train 3DGRT or 3DGUT scenes](#-2-train-3dgrt-or-3dgut-scenes)
- [ğŸ¥ 3. Rendering from Checkpoints](#-3-rendering-from-checkpoints)
  - [To visualize training progress interactively](#to-visualize-training-progress-interactively)
  - [To visualize a pre-trained checkpoint](#to-visualize-a-pre-trained-checkpoint)
- [ğŸ“‹ 4. Evaluations](#-4-evaluations)
  - [3DGRT](#3dgrt)
    - [MipNeRF360 Dataset](#mipnerf360-dataset)
  - [3DGUT](#3dgut)
    - [MipNeRF360 Dataset](#mipnerf360-dataset-1)
    - [Scannet++ Dataset](#scannet-dataset)
- [ğŸ› 5. Interactive Playground GUI](#-5-interactive-playground-gui)
- [ğŸ“ 6. Citations](#-6-citations)
- [ğŸ™ 7. Acknowledgements](#-7-acknowledgements)

## ğŸ”§ 1 Dependencies and Installation
- CUDA 11.8+ Compatible System
- For good performance with 3DGRT, we recommend using an NVIDIA GPU with Ray Tracing (RT) cores.
- Currently, only Linux environments are supported by the included install script (Windows support coming soon!)

<details> 
<summary> NOTE: gcc versions >11 (expand for details)</summary>

Currently the codebase requires gcc <= 11.  If your machine uses the compiler gcc-12 or newer (i.e., in Ubuntu 24.04), you may need to install and use gcc-11. 

First, install gcc 11:
```sh
sudo apt-get install gcc-11 g++-11
```

Then run the install script with the optional `WITH_GCC11` flag, which additionally configures the conda environment to use gcc-11:
```sh
./install_env.sh 3dgrut WITH_GCC11
```
</details>
</br>

To set up the environment using conda, first clone the repository and run `./install_env.sh` script as:

```bash
git clone --recursive https://github.com/nv-tlabs/3dgrut.git
cd 3dgrut

# You can install each component step by step following install_env.sh
chmod +x install_env.sh
./install_env.sh 3dgrut
conda activate 3dgrut
```

### Running with Docker

Build the docker image:
```bash
git clone --recursive https://github.com/nv-tlabs/3dgrut.git
cd 3dgrut
docker build . -t 3dgrut
````

Run it:
```bash
xhost +local:root
docker run -v --rm -it --gpus=all --net=host --ipc=host -v $PWD:/workspace --runtime=nvidia -e DISPLAY 3dgrut
```
> [!NOTE]
> Remember to set DISPLAY environment variable if you are running on a remote server from command line.

## ğŸ’» 2. Train 3DGRT or 3DGUT scenes

We provide different configurations for training using 3DGRT and 3DGUT models on common benchmark datasets. 
For example you can download [NeRF Synthetic dataset](https://www.kaggle.com/datasets/nguyenhung1903/nerf-synthetic-dataset), 
[MipNeRF360 dataset](https://jonbarron.info/mipnerf360/) or [ScanNet++](https://kaldir.vc.in.tum.de/scannetpp/), 
and then run one of the following commands:

```bash
# Train Lego with 3DGRT & 3DGUT
python train.py --config-name apps/nerf_synthetic_3dgrt.yaml path=data/nerf_synthetic/lego out_dir=runs experiment_name=lego_3dgrt
python train.py --config-name apps/nerf_synthetic_3dgut.yaml path=data/nerf_synthetic/lego out_dir=runs experiment_name=lego_3dgut


# Train Dog and mask with 3DGRT & 3DGUT
python train.py --config-name apps/nerf_synthetic_with_mask_3dgrt.yaml path=data/trans_synthetic/Dog_results_140 out_dir=runs experiment_name=dog_3dgrt
python train.py --config-name apps/nerf_synthetic_with_mask_3dgut.yaml path=data/trans_synthetic/Dog_results_140 out_dir=runs experiment_name=dog_3dgut


# Train Dog with mask with 3DGRT & 3DGUT
python train_with_mask.py --config-name apps/nerf_synthetic_with_mask_3dgrt.yaml path=data/trans_synthetic/Dog_results_140 out_dir=runs experiment_name=dog_3dgrt_masked
python train_with_mask.py --config-name apps/nerf_synthetic_with_mask_3dgut.yaml path=data/trans_synthetic/Dog_results_140 out_dir=runs experiment_name=dog_3dgut_masked

# Train Bonsai
CUDA_VISIBLE_DEVICES=1 python train.py --config-name apps/colmap_3dgrt.yaml path=data/mipnerf360/bonsai out_dir=runs experiment_name=bonsai_3dgrt dataset.downsample_factor=2 
python train.py --config-name apps/colmap_3dgut.yaml path=data/mipnerf360/bonsai out_dir=runs experiment_name=bonsai_3dgut dataset.downsample_factor=2 

# Train Eiko_ball
python train.py --config-name apps/colmap_3dgrt.yaml path=data/trans/eiko_ball out_dir=runs experiment_name=eiko_ball_3dgrt 
python train.py --config-name apps/colmap_3dgut.yaml path=data/trans/eiko_ball out_dir=runs experiment_name=eiko_ball_3dgut

# Train Eiko_ball_masked
CUDA_VISIBLE_DEVICES=0 python train.py --config-name apps/colmap_3dgrt.yaml path=data/trans/eiko_ball_masked out_dir=runs experiment_name=eiko_ball_masked_3dgrt 
CUDA_VISIBLE_DEVICES=0 python train.py --config-name apps/colmap_3dgut.yaml path=data/trans/eiko_ball_masked out_dir=runs experiment_name=eiko_ball_masked_3dgut

# Train Eiko_ball_masked_expanded 
CUDA_VISIBLE_DEVICES=0 python train.py --config-name apps/colmap_3dgrt.yaml path=data/trans/eiko_ball_masked_expanded out_dir=runs experiment_name=eiko_ball_masked_expanded_3dgrt 
CUDA_VISIBLE_DEVICES=0 python train.py --config-name apps/colmap_3dgut.yaml path=data/trans/eiko_ball_masked_expanded out_dir=runs experiment_name=eiko_ball_masked_expanded_3dgut



# Train Scannet++
python train.py --config-name apps/scannetpp_3dgut.yaml path=data/scannetpp/0a5c013435/dslr out_dir=runs experiment_name=0a5c013435_3dgut
```

> [!Note] 
> For ScanNet++, we expect the dataset to be preprocessed following [FisheyeGS](https://github.com/zmliao/Fisheye-GS?tab=readme-ov-file#prepare-training-data-on-scannet-dataset)'s method.

> [!Note]  
> If you're running from PyCharm IDE, enable rich console through:
> Run Configuration > Modify Options > Emulate terminal in output console*

## ğŸ¥ 3. Rendering from Checkpoints
Evaluate Checkpoint with Splatting / OptiX Tracer / Torch
```bash
python render.py --checkpoint runs/lego/ckpt_last.pt --out-dir outputs/eval
```


### To visualize training progress interactively
```bash
python train.py --config-name apps/nerf_synthetic_3dgut.yaml path=data/nerf_synthetic/lego with_gui=True 
```

### To visualize a pre-trained checkpoint
```bash
python train.py --config-name apps/nerf_synthetic_3dgut.yaml path=data/nerf_synthetic/lego with_gui=True test_last=False export_ingp.enabled=False resume=runs/lego/ckpt_last.pt 
```
> [!NOTE]
> Remember to set DISPLAY environment variable if you are running on a remote server from command line.

On start up, you might see a black screen, but you can use the GUI to navigate to correct camera views:
<img src="assets/train_gui_initial.jpg" height="400"/> 
<img src="assets/render_lego.jpg" height="400"/>

## ğŸ“‹ 4. Evaluations

We provide scripts to reproduce results reported in publications.

```bash
# Training
bash ./benchmark/mipnerf360_3dgut.sh <config-yaml>
# Rendering
bash ./benchmark/mipnerf360_3dgut_render.sh <config-yaml>
```

### 3DGRT

#### MipNeRF360 Dataset

### 3DGUT

#### MipNeRF360 Dataset

```bash
bash ./benchmark/mipnerf360.sh paper/3dgut/unsorted_colmap.yaml
```

Results for unsorted 3DGUT (Produced on RTX 5090):

|          | Bicycle | Bonsai  | Counter | Flower  | Garden  | Kitchen | Room    | Stump   | Treehill | *Average* |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|----------|-----------|
| train(s) | 835.93  | 476.00  | 468.86  | 681.15  | 665.59  | 502.89  | 447.66  | 682.58  | 669.83   | 608.28    |
| FPS      | 269.5   | 362.3   | 336.7   | 276.2   | 333.3   | 310.6   | 383.1   | 333.3   | 326.8    | 325.8     |
| PSNR     | 24.737  | 32.235  | 28.448  | 21.326  | 26.699  | 30.393  | 31.130  | 26.289  | 22.518   | 27.086    |


#### Scannet++ Dataset

```bash
bash ./benchmark/scannetpp.sh paper/3dgut/unsorted_scannetpp.yaml
```
> [!Note]
> We followed [FisheyeGS](https://github.com/zmliao/Fisheye-GS?tab=readme-ov-file#prepare-training-data-on-scannet-dataset)'s convention to prepare the dataset for fair comparisons

Results for unsorted 3DGUT (Produced on RTX 5090):

|          | 0a5c013435 | 8d563fc2cc | bb87c292ad | d415cc449b | e8ea9b4da8 | fe1733741f | *Average* |
|----------|------------|------------|------------|------------|------------|------------|-----------|
| train(s) | 298.09     | 295.64     | 330.89     | 405.95     | 288.53     | 371.71     |  331.80   |
| FPS      | 408.2      | 465.1      | 490.2      | 446.4      | 401.6      | 444.4      |  442.7    |
| PSNR     | 29.790     | 26.848     | 31.610     | 28.084     | 33.259     | 25.608     |  29.200   |

## ğŸ› 5. Interactive Playground GUI

The playground allows interactive exploration of pretrained scenes, with raytracing effects such as inserted objects, 
reflections, refractions, depth of field, and more.

Run the playground UI to visualize a pretrained scene with:
```
python playground.py --gs_object <ckpt_path>
```

See [Playground README](playground/README.md) for details.



## ğŸ“ 6. Citations

```
@article{loccoz20243dgrt,
    author = {Nicolas Moenne-Loccoz and Ashkan Mirzaei and Or Perel and Riccardo de Lutio and Janick Martinez Esturo and Gavriel State and Sanja Fidler and Nicholas Sharp and Zan Gojcic},
    title = {3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes},
    journal = {ACM Transactions on Graphics and SIGGRAPH Asia},
    year = {2024},
}
```

```
@article{wu20253dgut,
    title={3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting},
    author={Wu, Qi and Martinez Esturo, Janick and Mirzaei, Ashkan and Moenne-Loccoz, Nicolas and Gojcic, Zan},
    journal = {Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2025}
}
```

## ğŸ™ 7. Acknowledgements

We sincerely thank our colleagues for their valuable contributions to this project.

Hassan Abu Alhaija, Ronnie Sharif, Beau Perschall and Lars Fabiunke for assistance with assets.
Greg Muthler, Magnus Andersson, Maksim Eisenstein, Tanki Zhang, Nathan Morrical, Dietger van Antwerpen and John Burgess for performance feedback.
Thomas MÃ¼ller, Merlin Nimier-David, and Carsten Kolve for inspiration and pointers. 
Ziyu Chen, Clement Fuji-Tsang, Masha Shugrina, and George Kopanas for technical & experiment assistance,
and to Ramana Kiran and Shailesh Mishra for typo fixes.



<p align="center">
  <img height="100" src="assets/3dgrut_logo.png">
</p>

---
<p align="center">
  <img width="100%" src="assets/nvidia-hq-playground.gif">
</p>

æœ¬ä»“åº“æä¾›äº†**3Dé«˜æ–¯å…‰çº¿è¿½è¸ªï¼ˆ3DGRTï¼‰**å’Œ**3Dé«˜æ–¯æ— è¿¹å˜æ¢ï¼ˆ3DGUTï¼‰**çš„å®˜æ–¹å®ç°ã€‚ä¸ä¾èµ–äºå–·æº…çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œ3DGRTæ‰§è¡Œä½“ç§¯é«˜æ–¯ç²’å­çš„å…‰çº¿è¿½è¸ªã€‚è¿™ä½¿å¾—æ”¯æŒå…·æœ‰å¤æ‚ã€æ—¶é—´ä¾èµ–æ•ˆæœï¼ˆå¦‚æ»šåŠ¨å¿«é—¨ï¼‰çš„å¤±çœŸç›¸æœºæˆä¸ºå¯èƒ½ï¼ŒåŒæ—¶æœ‰æ•ˆæ¨¡æ‹Ÿæ¸²æŸ“ç°è±¡ï¼ˆå¦‚åå°„ã€æŠ˜å°„å’Œé˜´å½±ï¼‰æ‰€éœ€çš„æ¬¡çº§å…‰çº¿ã€‚ç„¶è€Œï¼Œ3DGRTéœ€è¦ä¸“ç”¨çš„å…‰çº¿è¿½è¸ªç¡¬ä»¶ï¼Œå¹¶ä¸”é€Ÿåº¦ä»ç„¶æ…¢äº3DGSã€‚

ä¸ºäº†å‡è½»è¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†3DGUTï¼Œå®ƒåœ¨å…‰æ …åŒ–æ¡†æ¶å†…æ”¯æŒå…·æœ‰å¤æ‚ã€æ—¶é—´ä¾èµ–æ•ˆæœçš„å¤±çœŸç›¸æœºï¼ŒåŒæ—¶ä¿æŒå…‰æ …åŒ–æ–¹æ³•çš„æ•ˆç‡ã€‚é€šè¿‡å¯¹é½3DGRTå’Œ3DGUTçš„æ¸²æŸ“å…¬å¼ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç§°ä¸º**3DGRUT**çš„æ··åˆæ–¹æ³•ã€‚è¿™ç§æŠ€æœ¯å…è®¸é€šè¿‡å…‰æ …åŒ–æ¸²æŸ“ä¸»å…‰çº¿ï¼Œé€šè¿‡å…‰çº¿è¿½è¸ªæ¸²æŸ“æ¬¡çº§å…‰çº¿ï¼Œç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œä»¥æé«˜æ€§èƒ½å’Œçµæ´»æ€§ã€‚

> __3Dé«˜æ–¯å…‰çº¿è¿½è¸ªï¼šå¿«é€Ÿè¿½è¸ªç²’å­åœºæ™¯__  
> [Nicolas Moenne-Loccoz*](https://www.linkedin.com/in/nicolas-moÃ«nne-loccoz-71040512/?original_referer=https%3A%2F%2Fwww%2Egoogle%2Ecom%2F&originalSubdomain=ca), [Ashkan Mirzaei*](https://ashmrz.github.io), [Or Perel](https://orperel.github.io/), [Riccardo De Lutio](https://riccardodelutio.github.io/), [Janick Martinez Esturo](https://jme.pub/),   
> [Gavriel State](https://www.linkedin.com/in/gavstate/?originalSubdomain=ca), [Sanja Fidler](https://www.cs.utoronto.ca/~fidler/), [Nicholas Sharp^](https://nmwsharp.com/), [Zan Gojcic^](https://zgojcic.github.io/) _(*,^ è¡¨ç¤ºåŒç­‰è´¡çŒ®)_  
> _SIGGRAPH Asia 2024ï¼ˆæœŸåˆŠè½¨é“ï¼‰_  
> __[é¡¹ç›®é¡µé¢](https://research.nvidia.com/labs/toronto-ai/3DGRT)&nbsp;/ [è®ºæ–‡](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_compressed.pdf)&nbsp;/ [è§†é¢‘](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_supplementary_video.mp4)&nbsp;/ [BibTeX](/-/raw/release/assets/3dgrt2024.bib)__

> __3DGUTï¼šåœ¨é«˜æ–¯å–·æº…ä¸­å¯ç”¨å¤±çœŸç›¸æœºå’Œæ¬¡çº§å…‰çº¿__  
> [Qi Wu*](https://wilsoncernwq.github.io/), [Janick Martinez Esturo*](https://jme.pub/), [Ashkan Mirzaei](https://ashmrz.github.io),   
> [Nicolas Moenne-Loccoz](https://www.linkedin.com/in/nicolas-moÃ«nne-loccoz-71040512/?original_referer=https%3A%2F%2Fwww%2Egoogle%2Ecom%2F&originalSubdomain=ca), [Zan Gojcic](https://zgojcic.github.io/)  _(* è¡¨ç¤ºåŒç­‰è´¡çŒ®)_  
> _CVPR 2025_  
> __[é¡¹ç›®é¡µé¢](https://research.nvidia.com/labs/toronto-ai/3DGUT)&nbsp;/ [è®ºæ–‡](https://research.nvidia.com/labs/toronto-ai/3DGUT/res/3DGUT_ready_main.pdf)&nbsp;/ [è§†é¢‘](https://research.nvidia.com/labs/toronto-ai/3DGUT/#supp_video)&nbsp;/ [BibTeX](/-/raw/release/assets/3dgut2025.bib)__


## ğŸ”¥ æ–°é—»
- âœ…[2025/03] åˆå§‹ä»£ç å‘å¸ƒï¼
- âœ…[2025/02] [3DGUT](https://research.nvidia.com/labs/toronto-ai/3DGUT/res/3DGUT_ready_main.pdf) è¢«æ¥å—åˆ°CVPR 2025ï¼
- âœ…[2024/08] [3DGRT](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_compressed.pdf) è¢«æ¥å—åˆ°SIGGRAPH Asia 2024ï¼

## ç›®å½•

- [ğŸ”¥ æ–°é—»](#-æ–°é—»)
- [ç›®å½•](#ç›®å½•)
- [ğŸ”§ 1 ä¾èµ–é¡¹å’Œå®‰è£…](#-1-ä¾èµ–é¡¹å’Œå®‰è£…)
- [ğŸ’» 2. è®­ç»ƒ3DGRTæˆ–3DGUTåœºæ™¯](#-2-è®­ç»ƒ3dgrtæˆ–3dgutåœºæ™¯)
- [ğŸ¥ 3. ä»æ£€æŸ¥ç‚¹æ¸²æŸ“](#-3-ä»æ£€æŸ¥ç‚¹æ¸²æŸ“)
  - [ä»¥äº¤äº’æ–¹å¼å¯è§†åŒ–è®­ç»ƒè¿›åº¦](#ä»¥äº¤äº’æ–¹å¼å¯è§†åŒ–è®­ç»ƒè¿›åº¦)
  - [å¯è§†åŒ–é¢„è®­ç»ƒæ£€æŸ¥ç‚¹](#å¯è§†åŒ–é¢„è®­ç»ƒæ£€æŸ¥ç‚¹)
- [ğŸ“‹ 4. è¯„ä¼°](#-4-è¯„ä¼°)
  - [3DGRT](#3dgrt)
    - [MipNeRF360 æ•°æ®é›†](#mipnerf360-æ•°æ®é›†)
  - [3DGUT](#3dgut)
    - [MipNeRF360 æ•°æ®é›†](#mipnerf360-æ•°æ®é›†-1)
    - [Scannet++ æ•°æ®é›†](#scannet-æ•°æ®é›†)
- [ğŸ› 5. äº¤äº’å¼æ¸¸ä¹åœºGUI](#-5-äº¤äº’å¼æ¸¸ä¹åœºgui)
- [ğŸ“ 6. å¼•ç”¨](#-6-å¼•ç”¨)
- [ğŸ™ 7. è‡´è°¢](#-7-è‡´è°¢)

## ğŸ”§ 1 ä¾èµ–é¡¹å’Œå®‰è£…
- CUDA 11.8+ å…¼å®¹ç³»ç»Ÿ
- ä¸ºäº†åœ¨3DGRTä¸­è·å¾—è‰¯å¥½çš„æ€§èƒ½ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨å…·æœ‰å…‰çº¿è¿½è¸ªï¼ˆRTï¼‰æ ¸å¿ƒçš„NVIDIA GPUã€‚
- ç›®å‰ï¼Œä»…æ”¯æŒLinuxç¯å¢ƒçš„å®‰è£…è„šæœ¬ï¼ˆWindowsæ”¯æŒå³å°†æ¨å‡ºï¼ï¼‰

<details> 
<summary> æ³¨æ„ï¼šgccç‰ˆæœ¬ >11ï¼ˆå±•å¼€ä»¥è·å–è¯¦ç»†ä¿¡æ¯ï¼‰</summary>

å½“å‰ä»£ç åº“è¦æ±‚gcc <= 11ã€‚å¦‚æœæ‚¨çš„æœºå™¨ä½¿ç”¨çš„æ˜¯gcc-12æˆ–æ›´æ–°ç‰ˆæœ¬çš„ç¼–è¯‘å™¨ï¼ˆä¾‹å¦‚ï¼Œåœ¨Ubuntu 24.04ä¸­ï¼‰ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…å¹¶ä½¿ç”¨gcc-11ã€‚

é¦–å…ˆï¼Œå®‰è£…gcc 11ï¼š
```sh
sudo apt-get install gcc-11 g++-11
```

ç„¶åä½¿ç”¨å¯é€‰çš„`WITH_GCC11`æ ‡å¿—è¿è¡Œå®‰è£…è„šæœ¬ï¼Œè¯¥æ ‡å¿—è¿˜ä¼šé…ç½®condaç¯å¢ƒä»¥ä½¿ç”¨gcc-11ï¼š
```sh
./install_env.sh 3dgrut WITH_GCC11
```
</details>
</br>

è¦ä½¿ç”¨condaè®¾ç½®ç¯å¢ƒï¼Œé¦–å…ˆå…‹éš†è¯¥ä»“åº“å¹¶è¿è¡Œ`./install_env.sh`è„šæœ¬ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
git clone --recursive https://github.com/nv-tlabs/3dgrut.git
cd 3dgrut

# æ‚¨å¯ä»¥æŒ‰ç…§install_env.shé€æ­¥å®‰è£…æ¯ä¸ªç»„ä»¶
chmod +x install_env.sh
./install_env.sh 3dgrut
conda activate 3dgrut
```

### ä½¿ç”¨Dockerè¿è¡Œ

æ„å»ºdockeré•œåƒï¼š
```bash
git clone --recursive https://github.com/nv-tlabs/3dgrut.git
cd 3dgrut
docker build . -t 3dgrut
````

è¿è¡Œå®ƒï¼š
```bash
xhost +local:root
docker run -v --rm -it --gpus=all --net=host --ipc=host -v $PWD:/workspace --runtime=nvidia -e DISPLAY 3dgrut
```
> [!æ³¨æ„]
> å¦‚æœæ‚¨ä»å‘½ä»¤è¡Œåœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œè¯·è®°å¾—è®¾ç½®DISPLAYç¯å¢ƒå˜é‡ã€‚

## ğŸ’» 2. è®­ç»ƒ3DGRTæˆ–3DGUTåœºæ™¯

æˆ‘ä»¬æä¾›äº†ä¸åŒçš„é…ç½®ï¼Œç”¨äºåœ¨å¸¸è§åŸºå‡†æ•°æ®é›†ä¸Šä½¿ç”¨3DGRTå’Œ3DGUTæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚
ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä¸‹è½½[NeRFåˆæˆæ•°æ®é›†](https://www.kaggle.com/datasets/nguyenhung1903/nerf-synthetic-dataset)ï¼Œ
[MipNeRF360æ•°æ®é›†](https://jonbarron.info/mipnerf360/)æˆ–[ScanNet++](https://kaldir.vc.in.tum.de/scannetpp/)ï¼Œ
ç„¶åè¿è¡Œä»¥ä¸‹å‘½ä»¤ä¹‹ä¸€ï¼š

```bash
# ä½¿ç”¨3DGRTå’Œ3DGUTè®­ç»ƒä¹é«˜
python train.py --config-name apps/nerf_synthetic_3dgrt.yaml path=data/nerf_synthetic/lego out_dir=runs experiment_name=lego_3dgrt
python train.py --config-name apps/nerf_synthetic_3dgut.yaml path=data/nerf_synthetic/lego out_dir=runs experiment_name=lego_3dgut

# è®­ç»ƒç›†æ ½
CUDA_VISIBLE_DEVICES=1 python train.py --config-name apps/colmap_3dgrt.yaml path=data/mipnerf360/bonsai out_dir=runs experiment_name=bonsai_3dgrt dataset.downsample_factor=2 
python train.py --config-name apps/colmap_3dgut.yaml path=data/mipnerf360/bonsai out_dir=runs experiment_name=bonsai_3dgut dataset.downsample_factor=2 

# è®­ç»ƒEiko_ball
python train.py --config-name apps/colmap_3dgrt.yaml path=data/trans/eiko_ball out_dir=runs experiment_name=eiko_ball_3dgrt 
python train.py --config-name apps/colmap_3dgut.yaml path=data/trans/eiko_ball out_dir=runs experiment_name=eiko_ball_3dgut dataset.downsample_factor=1 

# è®­ç»ƒScannet++
python train.py --config-name apps/scannetpp_3dgut.yaml path=data/scannetpp/0a5c013435/dslr out_dir=runs experiment_name=0a5c013435_3dgut
```

> [!æ³¨æ„] 
> å¯¹äºScanNet++ï¼Œæˆ‘ä»¬æœŸæœ›æ•°æ®é›†æŒ‰ç…§[FisheyeGS](https://github.com/zmliao/Fisheye-GS?tab=readme-ov-file#prepare-training-data-on-scannet-dataset)çš„æ–¹æ³•è¿›è¡Œé¢„å¤„ç†ã€‚

> [!æ³¨æ„]  
> å¦‚æœæ‚¨ä»PyCharm IDEè¿è¡Œï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨ä¸°å¯Œæ§åˆ¶å°ï¼š
> è¿è¡Œé…ç½® > ä¿®æ”¹é€‰é¡¹ > åœ¨è¾“å‡ºæ§åˆ¶å°ä¸­æ¨¡æ‹Ÿç»ˆç«¯*

## ğŸ¥ 3. ä»æ£€æŸ¥ç‚¹æ¸²æŸ“
ä½¿ç”¨å–·æº…/OptiXè¿½è¸ªå™¨/Torchè¯„ä¼°æ£€æŸ¥ç‚¹
```bash
python render.py --checkpoint runs/lego/ckpt_last.pt --out-dir outputs/eval
```


### ä»¥äº¤äº’æ–¹å¼å¯è§†åŒ–è®­ç»ƒè¿›åº¦
```bash
python train.py --config-name apps/nerf_synthetic_3dgut.yaml path=data/nerf_synthetic/lego with_gui=True 
```

### å¯è§†åŒ–é¢„è®­ç»ƒæ£€æŸ¥ç‚¹
```bash
python train.py --config-name apps/nerf_synthetic_3dgut.yaml path=data/nerf_synthetic/lego with_gui=True test_last=False export_ingp.enabled=False resume=runs/lego/ckpt_last.pt 
```
> [!æ³¨æ„]
> å¦‚æœæ‚¨ä»å‘½ä»¤è¡Œåœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œè¯·è®°å¾—è®¾ç½®DISPLAYç¯å¢ƒå˜é‡ã€‚

å¯åŠ¨æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ°é»‘å±ï¼Œä½†æ‚¨å¯ä»¥ä½¿ç”¨GUIå¯¼èˆªåˆ°æ­£ç¡®çš„ç›¸æœºè§†å›¾ï¼š
<img src="assets/train_gui_initial.jpg" height="400"/> 
<img src="assets/render_lego.jpg" height="400"/>

## ğŸ“‹ 4. è¯„ä¼°

æˆ‘ä»¬æä¾›è„šæœ¬ä»¥é‡ç°å‡ºç‰ˆç‰©ä¸­æŠ¥å‘Šçš„ç»“æœã€‚

```bash
# è®­ç»ƒ
bash ./benchmark/mipnerf360_3dgut.sh <config-yaml>
# æ¸²æŸ“
bash ./benchmark/mipnerf360_3dgut_render.sh <config-yaml>
```

### 3DGRT

#### MipNeRF360 æ•°æ®é›†

### 3DGUT

#### MipNeRF360 æ•°æ®é›†

```bash
bash ./benchmark/mipnerf360.sh paper/3dgut/unsorted_colmap.yaml
```

å¯¹äºæœªæ’åºçš„3DGUTï¼ˆåœ¨RTX 5090ä¸Šç”Ÿæˆçš„ç»“æœï¼‰ï¼š

|          | è‡ªè¡Œè½¦ | ç›†æ ½  | è®¡æ•°å™¨ | èŠ±å‰  | èŠ±å›­  | å¨æˆ¿ | æˆ¿é—´    | æ ‘æ¡©   | æ ‘ä¸˜   | *å¹³å‡* |
|----------|---------|---------|---------|---------|---------|---------|---------|---------|----------|-----------|
| train(s) | 835.93  | 476.00  | 468.86  | 681.15  | 665.59  | 502.89  | 447.66  | 682.58  | 669.83   | 608.28    |
| FPS      | 269.5   | 362.3   | 336.7   | 276.2   | 333.3   | 310.6   | 383.1   | 333.3   | 326.8    | 325.8     |
| PSNR     | 24.737  | 32.235  | 28.448  | 21.326  | 26.699  | 30.393  | 31.130  | 26.289  | 22.518   | 27.086    |


#### Scannet++ æ•°æ®é›†

```bash
bash ./benchmark/scannetpp.sh paper/3dgut/unsorted_scannetpp.yaml
```
> [!æ³¨æ„]
> æˆ‘ä»¬éµå¾ªäº†[FisheyeGS](https://github.com/zmliao/Fisheye-GS?tab=readme-ov-file#prepare-training-data-on-scannet-dataset)çš„çº¦å®šï¼Œä»¥å…¬å¹³æ¯”è¾ƒå‡†å¤‡æ•°æ®é›†

å¯¹äºæœªæ’åºçš„3DGUTï¼ˆåœ¨RTX 5090ä¸Šç”Ÿæˆçš„ç»“æœï¼‰ï¼š

|          | 0a5c013435 | 8d563fc2cc | bb87c292ad | d415cc449b | e8ea9b4da8 | fe1733741f | *å¹³å‡* |
|----------|------------|------------|------------|------------|------------|------------|-----------|
| train(s) | 298.09     | 295.64     | 330.89     | 405.95     | 288.53     | 371.71     |  331.80   |
| FPS      | 408.2      | 465.1      | 490.2      | 446.4      | 401.6      | 444.4      |  442.7    |
| PSNR     | 29.790     | 26.848     | 31.610     | 28.084     | 33.259     | 25.608     |  29.200   |

## ğŸ› 5. äº¤äº’å¼æ¸¸ä¹åœºGUI

æ¸¸ä¹åœºå…è®¸å¯¹é¢„è®­ç»ƒåœºæ™¯è¿›è¡Œäº¤äº’å¼æ¢ç´¢ï¼Œå…·æœ‰æ’å…¥å¯¹è±¡ã€åå°„ã€æŠ˜å°„ã€æ™¯æ·±ç­‰å…‰çº¿è¿½è¸ªæ•ˆæœã€‚

è¿è¡Œæ¸¸ä¹åœºUIä»¥å¯è§†åŒ–é¢„è®­ç»ƒåœºæ™¯ï¼š
```
python playground.py --gs_object <ckpt_path>
```

æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[æ¸¸ä¹åœºREADME](playground/README.md)ã€‚

## ğŸ“ 6. å¼•ç”¨

```
@article{loccoz20243dgrt,
    author = {Nicolas Moenne-Loccoz and Ashkan Mirzaei and Or Perel and Riccardo de Lutio and Janick Martinez Esturo and Gavriel State and Sanja Fidler and Nicholas Sharp and Zan Gojcic},
    title = {3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes},
    journal = {ACM Transactions on Graphics and SIGGRAPH Asia},
    year = {2024},
}
```

```
@article{wu20253dgut,
    title={3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting},
    author={Wu, Qi and Martinez Esturo, Janick and Mirzaei, Ashkan and Moenne-Loccoz, Nicolas and Gojcic, Zan},
    journal = {Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2025}
}
```

## ğŸ™ 7. è‡´è°¢

æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢æˆ‘ä»¬çš„åŒäº‹å¯¹æœ¬é¡¹ç›®çš„å®è´µè´¡çŒ®ã€‚

Hassan Abu Alhaijaã€Ronnie Sharifã€Beau Perschallå’ŒLars Fabiunkeåœ¨èµ„äº§æ–¹é¢æä¾›äº†å¸®åŠ©ã€‚
Greg Muthlerã€Magnus Anderssonã€Maksim Eisensteinã€Tanki Zhangã€Nathan Morricalã€Dietger van Antwerpenå’ŒJohn Burgessæä¾›äº†æ€§èƒ½åé¦ˆã€‚
Thomas MÃ¼llerã€Merlin Nimier-Davidå’ŒCarsten Kolveæä¾›äº†çµæ„Ÿå’Œå»ºè®®ã€‚ 
Ziyu Chenã€Clement Fuji-Tsangã€Masha Shugrinaå’ŒGeorge Kopanasæä¾›äº†æŠ€æœ¯å’Œå®éªŒæ”¯æŒï¼Œ
å¹¶æ„Ÿè°¢Ramana Kiranå’ŒShailesh Mishraçš„æ‹¼å†™é”™è¯¯ä¿®æ­£ã€‚










